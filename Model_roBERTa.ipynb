{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis 2020-2021: roBERTa \n",
    "\n",
    "In this notebook, we will create a roBERTa model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pattern.text.en import singularize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Create a function to clean the tweets\n",
    "def cleanTxt(text):\n",
    "    text = text.lower() # Convert everything to lower case\n",
    "    text = re.sub(r'@[a-zA-Z0-9]+', '', text) # Remove @mentions\n",
    "    text = re.sub(r'rt[\\s]+', '', text) # Remove RT (retweet symbol)\n",
    "    text = re.sub(r'&amp;', 'and', text) # Replace '&amp;' by 'and'\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text) # Remove hyper link  \n",
    "    #text = re.sub(r'\\d+', '0', text) # Replace all numbers by a zero\n",
    "    text = \" \".join([singularize(word) for word in tokenizer.tokenize(text) if word not in stop_words]) # Remove stopwords\n",
    "    #text = \" \".join([singularize(word) for word in text])\n",
    "    text = re.sub(r'[^\\w\\s#]', ' ', text) # Remove all non-alphanumeric symbols (excluding whitespace and # characters)\n",
    "    text = re.sub(r'\\s+', ' ', text) # Replace multiple whitespaces by a single whitespace\n",
    "    text = text.strip() # Remove whitespaces at the beginning and at the end\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
       "      <td>1</td>\n",
       "      <td>hur ray Ä saving Ä u Ä  Ä in Ä so Ä many Ä way Ä  Ä  Ä #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ä would Ä young Ä fighting Ä age Ä man Ä be Ä the Ä va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203</td>\n",
       "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ä illeg al Ä dump Ä their Ä kid Ä at Ä the Ä border Ä ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204</td>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>0</td>\n",
       "      <td>ny Ä time Ä  s n early Ä all Ä white s Ä state Ä pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>0</td>\n",
       "      <td>ban Ä in Ä br u sel Ä euro pe Ä leader Ä are Ä ignor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19196</td>\n",
       "      <td>@SamEnvers you unfollowed me? Fuck you pussy</td>\n",
       "      <td>0</td>\n",
       "      <td>Ä you Ä unf ollow ed Ä me Ä fuck Ä you Ä pussy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>19197</td>\n",
       "      <td>@DanReynolds STFU BITCH! AND YOU GO MAKE SOME ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ä st fu Ä bitch Ä and Ä you Ä go Ä make Ä some Ä sat a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>19198</td>\n",
       "      <td>@2beornotbeing Honey, as a fellow white chick,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ä honey Ä a Ä a Ä fellow Ä white Ä chick Ä let Ä me Ä t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>19199</td>\n",
       "      <td>I hate bitches who talk about niggaz with kids...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ä hate Ä bit ches Ä who Ä talk Ä about Ä n igg az Ä w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19200</td>\n",
       "      <td>@AnnCoulter @DonaldJTrumpJr You won the\" life ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ä  Ä you Ä won Ä the Ä life Ä time Ä recipient Ä for Ä ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS  \\\n",
       "0       201  Hurray, saving us $$$ in so many ways @potus @...   1   \n",
       "1       202  Why would young fighting age men be the vast m...   1   \n",
       "2       203  @KamalaHarris Illegals Dump their Kids at the ...   1   \n",
       "3       204  NY Times: 'Nearly All White' States Pose 'an A...   0   \n",
       "4       205  Orban in Brussels: European leaders are ignori...   0   \n",
       "...     ...                                                ...  ..   \n",
       "9995  19196       @SamEnvers you unfollowed me? Fuck you pussy   0   \n",
       "9996  19197  @DanReynolds STFU BITCH! AND YOU GO MAKE SOME ...   1   \n",
       "9997  19198  @2beornotbeing Honey, as a fellow white chick,...   0   \n",
       "9998  19199  I hate bitches who talk about niggaz with kids...   1   \n",
       "9999  19200  @AnnCoulter @DonaldJTrumpJr You won the\" life ...   1   \n",
       "\n",
       "                                           text_cleaned  \n",
       "0     hur ray Ä saving Ä u Ä  Ä in Ä so Ä many Ä way Ä  Ä  Ä #...  \n",
       "1     Ä would Ä young Ä fighting Ä age Ä man Ä be Ä the Ä va...  \n",
       "2     Ä illeg al Ä dump Ä their Ä kid Ä at Ä the Ä border Ä ...  \n",
       "3     ny Ä time Ä  s n early Ä all Ä white s Ä state Ä pos...  \n",
       "4     ban Ä in Ä br u sel Ä euro pe Ä leader Ä are Ä ignor...  \n",
       "...                                                 ...  \n",
       "9995           Ä you Ä unf ollow ed Ä me Ä fuck Ä you Ä pussy  \n",
       "9996  Ä st fu Ä bitch Ä and Ä you Ä go Ä make Ä some Ä sat a...  \n",
       "9997  Ä honey Ä a Ä a Ä fellow Ä white Ä chick Ä let Ä me Ä t...  \n",
       "9998  Ä hate Ä bit ches Ä who Ä talk Ä about Ä n igg az Ä w...  \n",
       "9999  Ä  Ä you Ä won Ä the Ä life Ä time Ä recipient Ä for Ä ...  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "    \n",
    "df_train = pd.read_csv('data/hateval2019_en_train.csv')\n",
    "df_dev = pd.read_csv('data/hateval2019_en_dev.csv')\n",
    "\n",
    "df_train_dev = df_train.append(df_dev, ignore_index=True)\n",
    "df_train_dev = df_train_dev.drop(['TR', 'AG'], axis=1)\n",
    "\n",
    "df_test = pd.read_csv('data/hateval2019_en_test.csv')\n",
    "df_test = df_test.drop(['TR', 'AG'], axis=1)\n",
    "\n",
    "# Clean the data\n",
    "\n",
    "df_train_dev['text_cleaned'] = df_train_dev['text'].apply(cleanTxt)\n",
    "df_test['text_cleaned'] = df_test['text'].apply(cleanTxt)\n",
    "df_train_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb844f35ab274d75acad69b7ec5b67de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=588.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63854b7cd5304dde895478275438cafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=898822.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818dda70d6a54560a5e8e5f2c054bdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=456318.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3fc7b5fb5542638d66af2ebd1b6838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c128a4061641bb9b6e206c96f903b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=498676425.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1) not-hate 0.9168\n",
      "2) hate 0.0832\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task='hate'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "\n",
    "#text = \"Good night ðŸ˜Š\"\n",
    "text = \"Hurray, saving us $$$ in so many ways @potus @realDonaldTrump #LockThemUp #BuildTheWall #EndDACA #BoycottNFL #BoycottNike\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) hate 0.7246\n",
      "2) not-hate 0.2754\n"
     ]
    }
   ],
   "source": [
    "text = \"This is outrageous! #StopIllegalImmigration  #MeritImmigration\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(text):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    if scores[0] >= 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27537116"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34243</td>\n",
       "      <td>@local1025 @njdotcom @GovMurphy Oh, I could ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh could gone taxe since current news nj guv w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30593</td>\n",
       "      <td>Several of the wild fires in #california and #...</td>\n",
       "      <td>0</td>\n",
       "      <td>several wild fire #californium #colorado inten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31427</td>\n",
       "      <td>@JudicialWatch My question is how do you reset...</td>\n",
       "      <td>0</td>\n",
       "      <td>question resettle refugee refugee go home coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31694</td>\n",
       "      <td>#Europe, you've got a problem!   We must hurry...</td>\n",
       "      <td>1</td>\n",
       "      <td>#europe got problem must hurry #buildthewall b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31865</td>\n",
       "      <td>This is outrageous! #StopIllegalImmigration  #...</td>\n",
       "      <td>1</td>\n",
       "      <td>outrageou #stopillegalimmigration #meritimmigr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>31368</td>\n",
       "      <td>you can never take a L off a real bitchðŸ˜© im ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>never take l real bitch im hotter ho chill w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>30104</td>\n",
       "      <td>@Brian_202 likes to call me a cunt &amp; a bitch b...</td>\n",
       "      <td>1</td>\n",
       "      <td>_202 like call cunt bitch tell truth can t handle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>31912</td>\n",
       "      <td>@kusha1a @Camio_the_wise @shoe0nhead 1. Never ...</td>\n",
       "      <td>1</td>\n",
       "      <td>_the_wise 1 never said taught 2 called bitch f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>31000</td>\n",
       "      <td>If i see and know you a hoe why would i hit yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>see know hoe would hit back lol bitch got new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>30870</td>\n",
       "      <td>You be chasing them hoes fuck what a bitch think</td>\n",
       "      <td>1</td>\n",
       "      <td>chasing ho fuck bitch think</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS  \\\n",
       "0     34243  @local1025 @njdotcom @GovMurphy Oh, I could ha...   0   \n",
       "1     30593  Several of the wild fires in #california and #...   0   \n",
       "2     31427  @JudicialWatch My question is how do you reset...   0   \n",
       "3     31694  #Europe, you've got a problem!   We must hurry...   1   \n",
       "4     31865  This is outrageous! #StopIllegalImmigration  #...   1   \n",
       "...     ...                                                ...  ..   \n",
       "2995  31368  you can never take a L off a real bitchðŸ˜© im ho...   1   \n",
       "2996  30104  @Brian_202 likes to call me a cunt & a bitch b...   1   \n",
       "2997  31912  @kusha1a @Camio_the_wise @shoe0nhead 1. Never ...   1   \n",
       "2998  31000  If i see and know you a hoe why would i hit yo...   1   \n",
       "2999  30870   You be chasing them hoes fuck what a bitch think   1   \n",
       "\n",
       "                                           text_cleaned  \n",
       "0     oh could gone taxe since current news nj guv w...  \n",
       "1     several wild fire #californium #colorado inten...  \n",
       "2     question resettle refugee refugee go home coun...  \n",
       "3     #europe got problem must hurry #buildthewall b...  \n",
       "4     outrageou #stopillegalimmigration #meritimmigr...  \n",
       "...                                                 ...  \n",
       "2995       never take l real bitch im hotter ho chill w  \n",
       "2996  _202 like call cunt bitch tell truth can t handle  \n",
       "2997  _the_wise 1 never said taught 2 called bitch f...  \n",
       "2998  see know hoe would hit back lol bitch got new ...  \n",
       "2999                        chasing ho fuck bitch think  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34243</td>\n",
       "      <td>@local1025 @njdotcom @GovMurphy Oh, I could ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh could gone taxe since current news nj guv w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30593</td>\n",
       "      <td>Several of the wild fires in #california and #...</td>\n",
       "      <td>1</td>\n",
       "      <td>several wild fire #californium #colorado inten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31427</td>\n",
       "      <td>@JudicialWatch My question is how do you reset...</td>\n",
       "      <td>1</td>\n",
       "      <td>question resettle refugee refugee go home coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31694</td>\n",
       "      <td>#Europe, you've got a problem!   We must hurry...</td>\n",
       "      <td>1</td>\n",
       "      <td>#europe got problem must hurry #buildthewall b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31865</td>\n",
       "      <td>This is outrageous! #StopIllegalImmigration  #...</td>\n",
       "      <td>1</td>\n",
       "      <td>outrageou #stopillegalimmigration #meritimmigr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>31368</td>\n",
       "      <td>you can never take a L off a real bitchðŸ˜© im ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>never take l real bitch im hotter ho chill w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>30104</td>\n",
       "      <td>@Brian_202 likes to call me a cunt &amp; a bitch b...</td>\n",
       "      <td>0</td>\n",
       "      <td>_202 like call cunt bitch tell truth can t handle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>31912</td>\n",
       "      <td>@kusha1a @Camio_the_wise @shoe0nhead 1. Never ...</td>\n",
       "      <td>0</td>\n",
       "      <td>_the_wise 1 never said taught 2 called bitch f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>31000</td>\n",
       "      <td>If i see and know you a hoe why would i hit yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>see know hoe would hit back lol bitch got new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>30870</td>\n",
       "      <td>You be chasing them hoes fuck what a bitch think</td>\n",
       "      <td>1</td>\n",
       "      <td>chasing ho fuck bitch think</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS  \\\n",
       "0     34243  @local1025 @njdotcom @GovMurphy Oh, I could ha...   0   \n",
       "1     30593  Several of the wild fires in #california and #...   1   \n",
       "2     31427  @JudicialWatch My question is how do you reset...   1   \n",
       "3     31694  #Europe, you've got a problem!   We must hurry...   1   \n",
       "4     31865  This is outrageous! #StopIllegalImmigration  #...   1   \n",
       "...     ...                                                ...  ..   \n",
       "2995  31368  you can never take a L off a real bitchðŸ˜© im ho...   1   \n",
       "2996  30104  @Brian_202 likes to call me a cunt & a bitch b...   0   \n",
       "2997  31912  @kusha1a @Camio_the_wise @shoe0nhead 1. Never ...   0   \n",
       "2998  31000  If i see and know you a hoe why would i hit yo...   1   \n",
       "2999  30870   You be chasing them hoes fuck what a bitch think   1   \n",
       "\n",
       "                                           text_cleaned  \n",
       "0     oh could gone taxe since current news nj guv w...  \n",
       "1     several wild fire #californium #colorado inten...  \n",
       "2     question resettle refugee refugee go home coun...  \n",
       "3     #europe got problem must hurry #buildthewall b...  \n",
       "4     outrageou #stopillegalimmigration #meritimmigr...  \n",
       "...                                                 ...  \n",
       "2995       never take l real bitch im hotter ho chill w  \n",
       "2996  _202 like call cunt bitch tell truth can t handle  \n",
       "2997  _the_wise 1 never said taught 2 called bitch f...  \n",
       "2998  see know hoe would hit back lol bitch got new ...  \n",
       "2999                        chasing ho fuck bitch think  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-9471171feade>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Evaluate the result of the pretrained_roberta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"scores_pretrained_roberta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import evaluate # here we import the local evaluate.ipynb jupyter notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df_test_roberta = df_test.copy()\n",
    "#df_test_roberta['text'] = df_test_count_norm['text'].apply(cleanTxt)\n",
    "#df_test_roberta['count_norm'] = df_test_count_norm['text'].apply(count_norm)\n",
    "df_test_roberta['HS'] = df_test_roberta['text'].apply(get_label)\n",
    "\n",
    "# Create prediction file for the pretrained_roberta\n",
    "df_test_roberta[['id', 'HS']].to_csv('predictions/pretrained_roberta.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_roberta[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# Evaluate the result of the pretrained_roberta\n",
    "evaluate.write_eval(\"scores_pretrained_roberta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from evaluate.ipynb\n",
      "taskA_fscore: 0.5565265328623641\n",
      "taskA_precision: 0.6947238565192636\n",
      "taskA_recall: 0.6286945812807881\n",
      "taskA_accuracy: 0.5776666666666667\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import evaluate # here we import the local evaluate.ipynb jupyter notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create prediction file for the pretrained_roberta\n",
    "df_test_roberta[['id', 'HS']].to_csv('predictions/pretrained_roberta.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_roberta[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# Evaluate the result of the pretrained_roberta\n",
    "evaluate.write_eval(\"scores_pretrained_roberta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskA_fscore: 0.608939376163911\n",
      "taskA_precision: 0.6660755293928309\n",
      "taskA_recall: 0.6468527640941434\n",
      "taskA_accuracy: 0.6133333333333333\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import evaluate # here we import the local evaluate.ipynb jupyter notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df_test_roberta_cleaned = df_test.copy()\n",
    "df_test_roberta_cleaned['HS'] = df_test_roberta_cleaned['text_cleaned'].apply(get_label)\n",
    "\n",
    "# Create prediction file for the pretrained_roberta_cleaned\n",
    "df_test_roberta_cleaned[['id', 'HS']].to_csv('predictions/pretrained_roberta_cleaned.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_roberta_cleaned[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# Evaluate the result of the pretrained_roberta_cleaned\n",
    "evaluate.write_eval(\"scores_pretrained_roberta_cleaned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
