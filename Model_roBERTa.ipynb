{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis 2020-2021: roBERTa \n",
    "\n",
    "In this notebook, we will create a roBERTa model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pattern.text.en import singularize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Create a function to clean the tweets\n",
    "def cleanTxt(text):\n",
    "    text = text.lower() # Convert everything to lower case\n",
    "    text = re.sub(r'@[a-zA-Z0-9]+', '', text) # Remove @mentions\n",
    "    text = re.sub(r'rt[\\s]+', '', text) # Remove RT (retweet symbol)\n",
    "    text = re.sub(r'&amp;', 'and', text) # Replace '&amp;' by 'and'\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text) # Remove hyper link  \n",
    "    #text = re.sub(r'\\d+', '0', text) # Replace all numbers by a zero\n",
    "    text = \" \".join([singularize(word) for word in tokenizer.tokenize(text) if word not in stop_words]) # Remove stopwords\n",
    "    #text = \" \".join([singularize(word) for word in text])\n",
    "    text = re.sub(r'[^\\w\\s#]', ' ', text) # Remove all non-alphanumeric symbols (excluding whitespace and # characters)\n",
    "    text = re.sub(r'\\s+', ' ', text) # Replace multiple whitespaces by a single whitespace\n",
    "    text = text.strip() # Remove whitespaces at the beginning and at the end\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
       "      <td>1</td>\n",
       "      <td>hur ray Ġsaving Ġu Ġ Ġin Ġso Ġmany Ġway Ġ Ġ Ġ#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ġwould Ġyoung Ġfighting Ġage Ġman Ġbe Ġthe Ġva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203</td>\n",
       "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ġilleg al Ġdump Ġtheir Ġkid Ġat Ġthe Ġborder Ġ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204</td>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>0</td>\n",
       "      <td>ny Ġtime Ġ s n early Ġall Ġwhite s Ġstate Ġpos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>0</td>\n",
       "      <td>ban Ġin Ġbr u sel Ġeuro pe Ġleader Ġare Ġignor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19196</td>\n",
       "      <td>@SamEnvers you unfollowed me? Fuck you pussy</td>\n",
       "      <td>0</td>\n",
       "      <td>Ġyou Ġunf ollow ed Ġme Ġfuck Ġyou Ġpussy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>19197</td>\n",
       "      <td>@DanReynolds STFU BITCH! AND YOU GO MAKE SOME ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ġst fu Ġbitch Ġand Ġyou Ġgo Ġmake Ġsome Ġsat a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>19198</td>\n",
       "      <td>@2beornotbeing Honey, as a fellow white chick,...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ġhoney Ġa Ġa Ġfellow Ġwhite Ġchick Ġlet Ġme Ġt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>19199</td>\n",
       "      <td>I hate bitches who talk about niggaz with kids...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ġhate Ġbit ches Ġwho Ġtalk Ġabout Ġn igg az Ġw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19200</td>\n",
       "      <td>@AnnCoulter @DonaldJTrumpJr You won the\" life ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ġ Ġyou Ġwon Ġthe Ġlife Ġtime Ġrecipient Ġfor Ġ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS  \\\n",
       "0       201  Hurray, saving us $$$ in so many ways @potus @...   1   \n",
       "1       202  Why would young fighting age men be the vast m...   1   \n",
       "2       203  @KamalaHarris Illegals Dump their Kids at the ...   1   \n",
       "3       204  NY Times: 'Nearly All White' States Pose 'an A...   0   \n",
       "4       205  Orban in Brussels: European leaders are ignori...   0   \n",
       "...     ...                                                ...  ..   \n",
       "9995  19196       @SamEnvers you unfollowed me? Fuck you pussy   0   \n",
       "9996  19197  @DanReynolds STFU BITCH! AND YOU GO MAKE SOME ...   1   \n",
       "9997  19198  @2beornotbeing Honey, as a fellow white chick,...   0   \n",
       "9998  19199  I hate bitches who talk about niggaz with kids...   1   \n",
       "9999  19200  @AnnCoulter @DonaldJTrumpJr You won the\" life ...   1   \n",
       "\n",
       "                                           text_cleaned  \n",
       "0     hur ray Ġsaving Ġu Ġ Ġin Ġso Ġmany Ġway Ġ Ġ Ġ#...  \n",
       "1     Ġwould Ġyoung Ġfighting Ġage Ġman Ġbe Ġthe Ġva...  \n",
       "2     Ġilleg al Ġdump Ġtheir Ġkid Ġat Ġthe Ġborder Ġ...  \n",
       "3     ny Ġtime Ġ s n early Ġall Ġwhite s Ġstate Ġpos...  \n",
       "4     ban Ġin Ġbr u sel Ġeuro pe Ġleader Ġare Ġignor...  \n",
       "...                                                 ...  \n",
       "9995           Ġyou Ġunf ollow ed Ġme Ġfuck Ġyou Ġpussy  \n",
       "9996  Ġst fu Ġbitch Ġand Ġyou Ġgo Ġmake Ġsome Ġsat a...  \n",
       "9997  Ġhoney Ġa Ġa Ġfellow Ġwhite Ġchick Ġlet Ġme Ġt...  \n",
       "9998  Ġhate Ġbit ches Ġwho Ġtalk Ġabout Ġn igg az Ġw...  \n",
       "9999  Ġ Ġyou Ġwon Ġthe Ġlife Ġtime Ġrecipient Ġfor Ġ...  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "    \n",
    "df_train = pd.read_csv('data/hateval2019_en_train.csv')\n",
    "df_dev = pd.read_csv('data/hateval2019_en_dev.csv')\n",
    "\n",
    "df_train_dev = df_train.append(df_dev, ignore_index=True)\n",
    "df_train_dev = df_train_dev.drop(['TR', 'AG'], axis=1)\n",
    "\n",
    "df_test = pd.read_csv('data/hateval2019_en_test.csv')\n",
    "df_test = df_test.drop(['TR', 'AG'], axis=1)\n",
    "\n",
    "# Clean the data\n",
    "\n",
    "df_train_dev['text_cleaned'] = df_train_dev['text'].apply(cleanTxt)\n",
    "df_test['text_cleaned'] = df_test['text'].apply(cleanTxt)\n",
    "df_train_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb844f35ab274d75acad69b7ec5b67de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=588.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63854b7cd5304dde895478275438cafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=898822.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818dda70d6a54560a5e8e5f2c054bdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=456318.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3fc7b5fb5542638d66af2ebd1b6838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c128a4061641bb9b6e206c96f903b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=498676425.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1) not-hate 0.9168\n",
      "2) hate 0.0832\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task='hate'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "\n",
    "#text = \"Good night 😊\"\n",
    "text = \"Hurray, saving us $$$ in so many ways @potus @realDonaldTrump #LockThemUp #BuildTheWall #EndDACA #BoycottNFL #BoycottNike\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) hate 0.7246\n",
      "2) not-hate 0.2754\n"
     ]
    }
   ],
   "source": [
    "text = \"This is outrageous! #StopIllegalImmigration  #MeritImmigration\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(text):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    if scores[0] >= 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27537116"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34243</td>\n",
       "      <td>@local1025 @njdotcom @GovMurphy Oh, I could ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh could gone taxe since current news nj guv w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30593</td>\n",
       "      <td>Several of the wild fires in #california and #...</td>\n",
       "      <td>0</td>\n",
       "      <td>several wild fire #californium #colorado inten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31427</td>\n",
       "      <td>@JudicialWatch My question is how do you reset...</td>\n",
       "      <td>0</td>\n",
       "      <td>question resettle refugee refugee go home coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31694</td>\n",
       "      <td>#Europe, you've got a problem!   We must hurry...</td>\n",
       "      <td>1</td>\n",
       "      <td>#europe got problem must hurry #buildthewall b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31865</td>\n",
       "      <td>This is outrageous! #StopIllegalImmigration  #...</td>\n",
       "      <td>1</td>\n",
       "      <td>outrageou #stopillegalimmigration #meritimmigr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>31368</td>\n",
       "      <td>you can never take a L off a real bitch😩 im ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>never take l real bitch im hotter ho chill w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>30104</td>\n",
       "      <td>@Brian_202 likes to call me a cunt &amp; a bitch b...</td>\n",
       "      <td>1</td>\n",
       "      <td>_202 like call cunt bitch tell truth can t handle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>31912</td>\n",
       "      <td>@kusha1a @Camio_the_wise @shoe0nhead 1. Never ...</td>\n",
       "      <td>1</td>\n",
       "      <td>_the_wise 1 never said taught 2 called bitch f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>31000</td>\n",
       "      <td>If i see and know you a hoe why would i hit yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>see know hoe would hit back lol bitch got new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>30870</td>\n",
       "      <td>You be chasing them hoes fuck what a bitch think</td>\n",
       "      <td>1</td>\n",
       "      <td>chasing ho fuck bitch think</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS  \\\n",
       "0     34243  @local1025 @njdotcom @GovMurphy Oh, I could ha...   0   \n",
       "1     30593  Several of the wild fires in #california and #...   0   \n",
       "2     31427  @JudicialWatch My question is how do you reset...   0   \n",
       "3     31694  #Europe, you've got a problem!   We must hurry...   1   \n",
       "4     31865  This is outrageous! #StopIllegalImmigration  #...   1   \n",
       "...     ...                                                ...  ..   \n",
       "2995  31368  you can never take a L off a real bitch😩 im ho...   1   \n",
       "2996  30104  @Brian_202 likes to call me a cunt & a bitch b...   1   \n",
       "2997  31912  @kusha1a @Camio_the_wise @shoe0nhead 1. Never ...   1   \n",
       "2998  31000  If i see and know you a hoe why would i hit yo...   1   \n",
       "2999  30870   You be chasing them hoes fuck what a bitch think   1   \n",
       "\n",
       "                                           text_cleaned  \n",
       "0     oh could gone taxe since current news nj guv w...  \n",
       "1     several wild fire #californium #colorado inten...  \n",
       "2     question resettle refugee refugee go home coun...  \n",
       "3     #europe got problem must hurry #buildthewall b...  \n",
       "4     outrageou #stopillegalimmigration #meritimmigr...  \n",
       "...                                                 ...  \n",
       "2995       never take l real bitch im hotter ho chill w  \n",
       "2996  _202 like call cunt bitch tell truth can t handle  \n",
       "2997  _the_wise 1 never said taught 2 called bitch f...  \n",
       "2998  see know hoe would hit back lol bitch got new ...  \n",
       "2999                        chasing ho fuck bitch think  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34243</td>\n",
       "      <td>@local1025 @njdotcom @GovMurphy Oh, I could ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh could gone taxe since current news nj guv w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30593</td>\n",
       "      <td>Several of the wild fires in #california and #...</td>\n",
       "      <td>1</td>\n",
       "      <td>several wild fire #californium #colorado inten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31427</td>\n",
       "      <td>@JudicialWatch My question is how do you reset...</td>\n",
       "      <td>1</td>\n",
       "      <td>question resettle refugee refugee go home coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31694</td>\n",
       "      <td>#Europe, you've got a problem!   We must hurry...</td>\n",
       "      <td>1</td>\n",
       "      <td>#europe got problem must hurry #buildthewall b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31865</td>\n",
       "      <td>This is outrageous! #StopIllegalImmigration  #...</td>\n",
       "      <td>1</td>\n",
       "      <td>outrageou #stopillegalimmigration #meritimmigr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>31368</td>\n",
       "      <td>you can never take a L off a real bitch😩 im ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>never take l real bitch im hotter ho chill w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>30104</td>\n",
       "      <td>@Brian_202 likes to call me a cunt &amp; a bitch b...</td>\n",
       "      <td>0</td>\n",
       "      <td>_202 like call cunt bitch tell truth can t handle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>31912</td>\n",
       "      <td>@kusha1a @Camio_the_wise @shoe0nhead 1. Never ...</td>\n",
       "      <td>0</td>\n",
       "      <td>_the_wise 1 never said taught 2 called bitch f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>31000</td>\n",
       "      <td>If i see and know you a hoe why would i hit yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>see know hoe would hit back lol bitch got new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>30870</td>\n",
       "      <td>You be chasing them hoes fuck what a bitch think</td>\n",
       "      <td>1</td>\n",
       "      <td>chasing ho fuck bitch think</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS  \\\n",
       "0     34243  @local1025 @njdotcom @GovMurphy Oh, I could ha...   0   \n",
       "1     30593  Several of the wild fires in #california and #...   1   \n",
       "2     31427  @JudicialWatch My question is how do you reset...   1   \n",
       "3     31694  #Europe, you've got a problem!   We must hurry...   1   \n",
       "4     31865  This is outrageous! #StopIllegalImmigration  #...   1   \n",
       "...     ...                                                ...  ..   \n",
       "2995  31368  you can never take a L off a real bitch😩 im ho...   1   \n",
       "2996  30104  @Brian_202 likes to call me a cunt & a bitch b...   0   \n",
       "2997  31912  @kusha1a @Camio_the_wise @shoe0nhead 1. Never ...   0   \n",
       "2998  31000  If i see and know you a hoe why would i hit yo...   1   \n",
       "2999  30870   You be chasing them hoes fuck what a bitch think   1   \n",
       "\n",
       "                                           text_cleaned  \n",
       "0     oh could gone taxe since current news nj guv w...  \n",
       "1     several wild fire #californium #colorado inten...  \n",
       "2     question resettle refugee refugee go home coun...  \n",
       "3     #europe got problem must hurry #buildthewall b...  \n",
       "4     outrageou #stopillegalimmigration #meritimmigr...  \n",
       "...                                                 ...  \n",
       "2995       never take l real bitch im hotter ho chill w  \n",
       "2996  _202 like call cunt bitch tell truth can t handle  \n",
       "2997  _the_wise 1 never said taught 2 called bitch f...  \n",
       "2998  see know hoe would hit back lol bitch got new ...  \n",
       "2999                        chasing ho fuck bitch think  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-9471171feade>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Evaluate the result of the pretrained_roberta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"scores_pretrained_roberta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import evaluate # here we import the local evaluate.ipynb jupyter notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df_test_roberta = df_test.copy()\n",
    "#df_test_roberta['text'] = df_test_count_norm['text'].apply(cleanTxt)\n",
    "#df_test_roberta['count_norm'] = df_test_count_norm['text'].apply(count_norm)\n",
    "df_test_roberta['HS'] = df_test_roberta['text'].apply(get_label)\n",
    "\n",
    "# Create prediction file for the pretrained_roberta\n",
    "df_test_roberta[['id', 'HS']].to_csv('predictions/pretrained_roberta.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_roberta[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# Evaluate the result of the pretrained_roberta\n",
    "evaluate.write_eval(\"scores_pretrained_roberta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from evaluate.ipynb\n",
      "taskA_fscore: 0.5565265328623641\n",
      "taskA_precision: 0.6947238565192636\n",
      "taskA_recall: 0.6286945812807881\n",
      "taskA_accuracy: 0.5776666666666667\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import evaluate # here we import the local evaluate.ipynb jupyter notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create prediction file for the pretrained_roberta\n",
    "df_test_roberta[['id', 'HS']].to_csv('predictions/pretrained_roberta.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_roberta[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# Evaluate the result of the pretrained_roberta\n",
    "evaluate.write_eval(\"scores_pretrained_roberta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskA_fscore: 0.608939376163911\n",
      "taskA_precision: 0.6660755293928309\n",
      "taskA_recall: 0.6468527640941434\n",
      "taskA_accuracy: 0.6133333333333333\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import evaluate # here we import the local evaluate.ipynb jupyter notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df_test_roberta_cleaned = df_test.copy()\n",
    "df_test_roberta_cleaned['HS'] = df_test_roberta_cleaned['text_cleaned'].apply(get_label)\n",
    "\n",
    "# Create prediction file for the pretrained_roberta_cleaned\n",
    "df_test_roberta_cleaned[['id', 'HS']].to_csv('predictions/pretrained_roberta_cleaned.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_roberta_cleaned[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# Evaluate the result of the pretrained_roberta_cleaned\n",
    "evaluate.write_eval(\"scores_pretrained_roberta_cleaned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
