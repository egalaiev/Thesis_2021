{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis 2020-2021: Hate Speech Detection\n",
    "## Baselines Subtask A\n",
    "\n",
    "The following two baselines have been considered by the organizers of this competition in order to provide a benchmark for the comparison of the submitted systems: \n",
    "1. The MFC (Most Frequent Classifier) baseline: Trivial model that assigns the most frequent label, estimated on the\n",
    "training set, to all the instances in the test set.\n",
    "2. The SVC (Support Vector Classifier) baseline: Linear Support Vector Machine (SVM) based on a TF-IDF representation, where the hyper-parameters are the default values set by the scikit-learn Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import import_ipynb\n",
    "import evaluate # here we import the local evaluate.ipynb jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by reading the training and development data into a pandas dataframe. \n",
    "Columns TR and AG columns are removed as they are irrelevant for Subtask A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                               text  HS  TR  AG\n",
      "0      201  Hurray, saving us $$$ in so many ways @potus @...   1   0   0\n",
      "1      202  Why would young fighting age men be the vast m...   1   0   0\n",
      "2      203  @KamalaHarris Illegals Dump their Kids at the ...   1   0   0\n",
      "3      204  NY Times: 'Nearly All White' States Pose 'an A...   0   0   0\n",
      "4      205  Orban in Brussels: European leaders are ignori...   0   0   0\n",
      "...    ...                                                ...  ..  ..  ..\n",
      "8995  9196  @mmdwriter @JRubinBlogger @BenSasse I am proud...   0   0   0\n",
      "8996  9197  @CheriJacobus Hollywood is complicit in the ra...   0   0   0\n",
      "8997  9198  @amaziah_filani What a fucking cunt I hate see...   1   1   1\n",
      "8998  9199                  Hysterical woman like @CoryBooker   0   0   0\n",
      "8999  9200  Nearly every woman I know has #meToo in their ...   0   0   0\n",
      "\n",
      "[9000 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203</td>\n",
       "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204</td>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19196</td>\n",
       "      <td>@SamEnvers you unfollowed me? Fuck you pussy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>19197</td>\n",
       "      <td>@DanReynolds STFU BITCH! AND YOU GO MAKE SOME ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>19198</td>\n",
       "      <td>@2beornotbeing Honey, as a fellow white chick,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>19199</td>\n",
       "      <td>I hate bitches who talk about niggaz with kids...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19200</td>\n",
       "      <td>@AnnCoulter @DonaldJTrumpJr You won the\" life ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS\n",
       "0       201  Hurray, saving us $$$ in so many ways @potus @...   1\n",
       "1       202  Why would young fighting age men be the vast m...   1\n",
       "2       203  @KamalaHarris Illegals Dump their Kids at the ...   1\n",
       "3       204  NY Times: 'Nearly All White' States Pose 'an A...   0\n",
       "4       205  Orban in Brussels: European leaders are ignori...   0\n",
       "...     ...                                                ...  ..\n",
       "9995  19196       @SamEnvers you unfollowed me? Fuck you pussy   0\n",
       "9996  19197  @DanReynolds STFU BITCH! AND YOU GO MAKE SOME ...   1\n",
       "9997  19198  @2beornotbeing Honey, as a fellow white chick,...   0\n",
       "9998  19199  I hate bitches who talk about niggaz with kids...   1\n",
       "9999  19200  @AnnCoulter @DonaldJTrumpJr You won the\" life ...   1\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "    \n",
    "df_train = pd.read_csv('data/hateval2019_en_train.csv')\n",
    "df_dev = pd.read_csv('data/hateval2019_en_dev.csv')\n",
    "print(df_train)\n",
    "df_train_dev = df_train.append(df_dev, ignore_index=True)\n",
    "df_train_dev = df_train_dev.drop(['TR', 'AG'], axis=1)\n",
    "\n",
    "df_test = pd.read_csv('data/hateval2019_en_test.csv')\n",
    "df_test = df_test.drop(['TR', 'AG'], axis=1)\n",
    "\n",
    "df_train_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The English dataset is composed out of 13.000 tweets. Out of these tweets, 10.000 are meant for training and development (9.000 training tweets + 1.000 development tweets). As expected, we have 10.000 rows in this dataframe because we have appended both training and development data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train_dev.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Plot some great visualizations with this DATA!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MFC baseline\n",
    "#### Now we will program the MFC (Most Frequent Classifier Trivial) baseline, which assigns the most frequent label, estimated on the training set, to all the instances in the test set.\n",
    "\n",
    "First, we compute the most frequent label for HS (Hate Speech), estimated on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5790\n",
      "1    4210\n",
      "Name: HS, dtype: int64\n",
      "The most frequent label for HS is: 0. This means that most tweets in the training set are not labelled as hate speech.\n"
     ]
    }
   ],
   "source": [
    "print(df_train_dev['HS'].value_counts())\n",
    "most_frequent_label = df_train_dev['HS'].value_counts().index[0]\n",
    "print(f'The most frequent label for HS is: {most_frequent_label}. This means that most tweets in the training set are not labelled as hate speech.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we read the test set into a dataframe and assign to it the most frequent label that we just computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34243</td>\n",
       "      <td>@local1025 @njdotcom @GovMurphy Oh, I could ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30593</td>\n",
       "      <td>Several of the wild fires in #california and #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31427</td>\n",
       "      <td>@JudicialWatch My question is how do you reset...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31694</td>\n",
       "      <td>#Europe, you've got a problem!   We must hurry...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31865</td>\n",
       "      <td>This is outrageous! #StopIllegalImmigration  #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>31368</td>\n",
       "      <td>you can never take a L off a real bitchðŸ˜© im ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>30104</td>\n",
       "      <td>@Brian_202 likes to call me a cunt &amp; a bitch b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>31912</td>\n",
       "      <td>@kusha1a @Camio_the_wise @shoe0nhead 1. Never ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>31000</td>\n",
       "      <td>If i see and know you a hoe why would i hit yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>30870</td>\n",
       "      <td>You be chasing them hoes fuck what a bitch think</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS\n",
       "0     34243  @local1025 @njdotcom @GovMurphy Oh, I could ha...   0\n",
       "1     30593  Several of the wild fires in #california and #...   0\n",
       "2     31427  @JudicialWatch My question is how do you reset...   0\n",
       "3     31694  #Europe, you've got a problem!   We must hurry...   0\n",
       "4     31865  This is outrageous! #StopIllegalImmigration  #...   0\n",
       "...     ...                                                ...  ..\n",
       "2995  31368  you can never take a L off a real bitchðŸ˜© im ho...   0\n",
       "2996  30104  @Brian_202 likes to call me a cunt & a bitch b...   0\n",
       "2997  31912  @kusha1a @Camio_the_wise @shoe0nhead 1. Never ...   0\n",
       "2998  31000  If i see and know you a hoe why would i hit yo...   0\n",
       "2999  30870   You be chasing them hoes fuck what a bitch think   0\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_mfc = df_test.copy()\n",
    "df_test_mfc['HS'] = [most_frequent_label]*df_test_mfc.shape[0]\n",
    "df_test_mfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The macro-averaged F1 score for the MFC baseline is: 0.36708860759493667\n"
     ]
    }
   ],
   "source": [
    "# Compute the F1-score manually\n",
    "f1_mfc = f1_score(df_test['HS'].values, df_test_mfc['HS'].values, average='macro')\n",
    "print(f'The macro-averaged F1 score for the MFC baseline is: {f1_mfc}') \n",
    "\n",
    "# Great! This corresponds with the paper!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskA_fscore: 0.36708860759493667\n",
      "taskA_precision: 0.29\n",
      "taskA_recall: 0.5\n",
      "taskA_accuracy: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Create prediction file for the mfc_baseline\n",
    "df_test_mfc[['id', 'HS']].to_csv('predictions/mfc_baseline.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_mfc[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# Evaluate the result of the mfc_baseline\n",
    "evaluate.write_eval(\"scores_mfc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1740,    0],\n",
       "       [1260,    0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df_test.HS, df_test_mfc.HS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(clf, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVC baseline\n",
    "#### Now we will program the SVM (Linear Support Vector Machine) baseline, which is based on a TF-IDF representation, where the hyper-parameters are the default values set by the scikit-learn Python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The macro-averaged F1 score for the SVC baseline is: 0.43130790319531104\n",
      "taskA_fscore: 0.43130790319531104\n",
      "taskA_precision: 0.6281625422133643\n",
      "taskA_recall: 0.5506841817186645\n",
      "taskA_accuracy: 0.4866666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train = df_train_dev.text\n",
    "X_test = df_test.text\n",
    "y_train = df_train_dev.HS\n",
    "y_test = df_test.HS\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# train classifier\n",
    "clf = SVC().fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "f1_svc = f1_score(y_test.values, predictions, average='macro')\n",
    "print(f'The macro-averaged F1 score for the SVC baseline is: {f1_svc}')\n",
    "\n",
    "# Does NOT correspond with the paper!!! (paper SVC f1-score for Subtask A: 0.451) TODO: FIX model \n",
    "\n",
    "df_test_svc = df_test.copy()\n",
    "df_test_svc['HS'] = predictions\n",
    "\n",
    "# Create prediction file for the svc_baseline\n",
    "df_test_svc[['id', 'HS']].to_csv('predictions/svc_baseline.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_svc[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# # Evaluate the result of the svc_baseline\n",
    "evaluate.write_eval(\"scores_svc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 262, 1478],\n",
       "       [  62, 1198]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_test.HS, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(clf, X_test, y_test)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved versions of TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_dev.text\n",
    "X_test = df_test.text\n",
    "y_train = df_train_dev.HS\n",
    "y_test = df_test.HS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The macro-averaged F1 score: 0.5069024424026963\n",
      "taskA_fscore: 0.5069024424026963\n",
      "taskA_precision: 0.5985040567951319\n",
      "taskA_recall: 0.5708812260536398\n",
      "taskA_accuracy: 0.5253333333333333\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the TF-IDF model using Logistic Regression as the classifier (+ normalized input data)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_train = df_train_dev.text\n",
    "X_test = df_test.text\n",
    "y_train = df_train_dev.HS\n",
    "y_test = df_test.HS\n",
    "\n",
    "# Create TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = preprocessing.StandardScaler().fit(X_train.toarray())\n",
    "X_train_scaled = scaler.transform(X_train.toarray())\n",
    "X_test_scaled = scaler.transform(X_test.toarray())\n",
    "\n",
    "# train classifier\n",
    "clf = LogisticRegression().fit(X_train_scaled, y_train)\n",
    "predictions_scaled = clf.predict(X_test_scaled)\n",
    "f1_svc = f1_score(y_test.values, predictions_scaled, average='macro')\n",
    "print(f'The macro-averaged F1 score: {f1_svc}')\n",
    "\n",
    "df_test_logreg_scaled = df_test.copy()\n",
    "df_test_logreg_scaled['HS'] = predictions_scaled\n",
    "\n",
    "# Create prediction file for the tf_idf_logreg\n",
    "df_test_logreg_scaled[['id', 'HS']].to_csv('predictions/tf_idf_logreg.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_logreg_scaled[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# # Evaluate the result of the svc_baseline\n",
    "evaluate.write_eval(\"scores_tf_idf_logreg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The macro-averaged F1 score: 0.5069024424026963\n",
      "taskA_fscore: 0.5069024424026963\n",
      "taskA_precision: 0.5985040567951319\n",
      "taskA_recall: 0.5708812260536398\n",
      "taskA_accuracy: 0.5253333333333333\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the TF-IDF model using Logistic Regression as the classifier (+ normalized input data)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_train = df_train_dev.text\n",
    "X_test = df_test.text\n",
    "y_train = df_train_dev.HS\n",
    "y_test = df_test.HS\n",
    "\n",
    "# Create TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = preprocessing.StandardScaler().fit(X_train.toarray())\n",
    "X_train_scaled = scaler.transform(X_train.toarray())\n",
    "X_test_scaled = scaler.transform(X_test.toarray())\n",
    "\n",
    "# Apply PCA\n",
    "pca = decomposition.PCA()\n",
    "X_train_scaled_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_scaled_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# train classifier\n",
    "clf = LogisticRegression().fit(X_train_scaled_pca, y_train)\n",
    "predictions_scaled = clf.predict(X_test_scaled_pca)\n",
    "f1_svc = f1_score(y_test.values, predictions_scaled, average='macro')\n",
    "print(f'The macro-averaged F1 score: {f1_svc}')\n",
    "\n",
    "df_test_logreg_scaled = df_test.copy()\n",
    "df_test_logreg_scaled['HS'] = predictions_scaled\n",
    "\n",
    "# Create prediction file for the tf_idf_logreg\n",
    "df_test_logreg_scaled[['id', 'HS']].to_csv('predictions/tf_idf_logreg.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_logreg_scaled[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# # Evaluate the result of the svc_baseline\n",
    "evaluate.write_eval(\"scores_tf_idf_logreg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 63 candidates, totalling 315 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done 148 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=5)]: Done 306 out of 315 | elapsed:   20.7s remaining:    0.5s\n",
      "[Parallel(n_jobs=5)]: Done 315 out of 315 | elapsed:   21.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score:  0.7231216895431565\n",
      "Best parameters:  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the TF-IDF model using Logistic Regression as the classifier (+ normalized input data + GridSearch optimization)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_train = df_train_dev.text\n",
    "X_test = df_test.text\n",
    "y_train = df_train_dev.HS\n",
    "y_test = df_test.HS\n",
    "\n",
    "# Create TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = preprocessing.StandardScaler().fit(X_train.toarray())\n",
    "X_train_scaled = scaler.transform(X_train.toarray())\n",
    "X_test_scaled = scaler.transform(X_test.toarray())\n",
    "\n",
    "f1 = make_scorer(f1_score , average='macro')\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'solver': ('newton-cg', 'lbfgs', 'liblinear'), 'penalty': ('l1', 'l2', 'elasticnet')}\n",
    "grid = GridSearchCV(estimator=LogisticRegression(), param_grid=params, cv=5, scoring=f1, verbose=5, n_jobs=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: \", grid.best_score_)\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The macro-averaged F1 score: 0.45295218358992884\n",
      "taskA_fscore: 0.45295218358992884\n",
      "taskA_precision: 0.6391066708480803\n",
      "taskA_recall: 0.5623152709359606\n",
      "taskA_accuracy: 0.5006666666666667\n"
     ]
    }
   ],
   "source": [
    "# train classifier\n",
    "clf = LogisticRegression(C=10, penalty='l2', solver='liblinear').fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "f1 = f1_score(y_test.values, predictions, average='macro')\n",
    "print(f'The macro-averaged F1 score: {f1}')\n",
    "\n",
    "df_test_optimal = df_test.copy()\n",
    "df_test_optimal['HS'] = predictions\n",
    "\n",
    "# Create prediction file for the tf_idf_optimal\n",
    "df_test_optimal[['id', 'HS']].to_csv('predictions/tf_idf_optimal.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_optimal[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# # Evaluate the result of the tf_idf_optimal\n",
    "evaluate.write_eval(\"scores_tf_idf_optimal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The macro-averaged F1 score: 0.4994436912363046\n",
      "taskA_fscore: 0.4994436912363046\n",
      "taskA_precision: 0.5944618868601118\n",
      "taskA_recall: 0.5663245758073344\n",
      "taskA_accuracy: 0.5196666666666667\n"
     ]
    }
   ],
   "source": [
    "# train classifier\n",
    "clf = LogisticRegression(C=10, penalty='l2', solver='liblinear').fit(X_train_scaled, y_train)\n",
    "predictions = clf.predict(X_test_scaled)\n",
    "f1 = f1_score(y_test.values, predictions, average='macro')\n",
    "print(f'The macro-averaged F1 score: {f1}')\n",
    "\n",
    "df_test_scaled = df_test.copy()\n",
    "df_test_scaled['HS'] = predictions\n",
    "\n",
    "# Create prediction file for the tf_idf_scaled\n",
    "df_test_scaled[['id', 'HS']].to_csv('predictions/tf_idf_scaled.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_scaled[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# # Evaluate the result of the tf_idf_scaled\n",
    "evaluate.write_eval(\"scores_tf_idf_scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The macro-averaged F1 score: 0.3901300391242303\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ae7e15b8be55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mdf_test_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mdf_test_scaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'HS'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# Create prediction file for the tf_idf_scaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the TF-IDF model using Random Forest Classifier (+ normalized input data)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train = df_train_dev.text\n",
    "X_test = df_test.text\n",
    "y_train = df_train_dev.HS\n",
    "y_test = df_test.HS\n",
    "\n",
    "# Create TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = preprocessing.StandardScaler().fit(X_train.toarray())\n",
    "X_train_scaled = scaler.transform(X_train.toarray())\n",
    "X_test_scaled = scaler.transform(X_test.toarray())\n",
    "\n",
    "# train classifier\n",
    "clf = RandomForestClassifier().fit(X_train_scaled, y_train)\n",
    "predictions_scaled = clf.predict(X_test_scaled)\n",
    "f1 = f1_score(y_test.values, predictions_scaled, average='macro')\n",
    "print(f'The macro-averaged F1 score: {f1}')\n",
    "\n",
    "df_test_scaled = df_test.copy()\n",
    "df_test_scaled['HS'] = predictions_scaled\n",
    "\n",
    "# Create prediction file for the tf_idf_scaled\n",
    "df_test_scaled[['id', 'HS']].to_csv('predictions/tf_idf_scaled.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_scaled[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# # Evaluate the result of the tf_idf_scaled\n",
    "evaluate.write_eval(\"scores_tf_idf_scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-bdf9cd5d5b79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;31m# Fitting the grid search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m \u001b[0mclf_GS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;31m# Viewing The Best Parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best Penalty:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_GS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logistic_Reg__penalty'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mC\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m \u001b[1;34m'np.ascontiguousarray'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \"\"\"\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'arpack'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'randomized'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             raise ValueError(\"Unrecognized svd_solver='{0}'\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit_truncated\u001b[1;34m(self, X, n_components, svd_solver)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msvd_solver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'randomized'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             \u001b[1;31m# sign flipping is done inside\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             U, S, V = randomized_svd(X, n_components=n_components,\n\u001b[0m\u001b[0;32m    543\u001b[0m                                      \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterated_power\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m                                      \u001b[0mflip_sign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36mrandomized_svd\u001b[1;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m     Q = randomized_range_finder(\n\u001b[0m\u001b[0;32m    350\u001b[0m         \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_random\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[0mpower_iteration_normalizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpower_iteration_normalizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36mrandomized_range_finder\u001b[1;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[0mQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mpower_iteration_normalizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'LU'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m             \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mpower_iteration_normalizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'QR'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#print('**How to optimize hyper-parameters of a LR model using Grid Search in Python**')\n",
    "   \n",
    "# loading libraries\n",
    "import numpy as np\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Loading the dataset\n",
    "X_train = df_train_dev.text\n",
    "X_test = df_test.text\n",
    "y_train = df_train_dev.HS\n",
    "y_test = df_test.HS\n",
    "\n",
    "# Creating an TF-IDF object\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Creating an scaler object\n",
    "#std_slc = StandardScaler(with_mean=False)\n",
    "scaler = StandardScaler().fit(X_train.toarray())\n",
    "X_train_scaled = scaler.transform(X_train.toarray())\n",
    "#X_test_scaled = scaler.transform(X_test.toarray())\n",
    "\n",
    "# Creating a pca object\n",
    "pca = decomposition.PCA()\n",
    "#svd = TruncatedSVD()\n",
    "\n",
    "# Creating F1-score\n",
    "f1 = make_scorer(f1_score , average='macro')\n",
    "\n",
    "# Creating a logistic regression object\n",
    "logistic_Reg = linear_model.LogisticRegression()\n",
    "\n",
    "# Creating a pipeline of three steps. First, standardizing the data.\n",
    "# Second, tranforming the data with PCA.\n",
    "# Third, training a logistic regression on the data.\n",
    "pipe = Pipeline(steps=[#('std_slc', std_slc),\n",
    "                       ('pca', pca),\n",
    "                       ('logistic_Reg', logistic_Reg)])\n",
    "\n",
    "# Creating Parameter Space\n",
    "# Creating a list of a sequence of integers from 1 to 30 (the number of features in X + 1)\n",
    "n_components = list(range(1,10,1))\n",
    "#n_components = list(range(1,X_train.shape[1]+1,1))\n",
    "\n",
    "# Creating a list of values of the regularization parameter\n",
    "C = np.logspace(-4, 15, 50)\n",
    "# Creating a list of options for the regularization penalty\n",
    "penalty = ['l1', 'l2']\n",
    "# Creating a dictionary of all the parameter options \n",
    "# Note has we can access the parameters of steps of a pipeline by using '__â€™\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                  logistic_Reg__C=C,\n",
    "                  logistic_Reg__penalty=penalty,\n",
    "                  logistic_Reg__verbose=[True])\n",
    "\n",
    "# Conducting Parameter Optmization With Pipeline\n",
    "# Creating a grid search object\n",
    "clf_GS = GridSearchCV(pipe, parameters, scoring=f1)\n",
    "\n",
    "# Fitting the grid search\n",
    "clf_GS.fit(X_train_scaled, y_train)\n",
    "# Viewing The Best Parameters\n",
    "print('Best Penalty:', clf_GS.best_estimator_.get_params()['logistic_Reg__penalty'])\n",
    "print('Best C:', clf_GS.best_estimator_.get_params()['logistic_Reg__C'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['logistic_Reg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524],\n",
       "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
       "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
       "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
       "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
       "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRA: Easy TF-IDF example to understand how the TfidfVectorizer() works.\n",
    "\n",
    "corpus = ['This is the first document.',\n",
    "          'This document is the second document.',\n",
    "          'And this is the third one.',\n",
    "          'Is this the first document?']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "X = X.toarray()\n",
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
