{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis 2020-2021: Hate Speech Detection\n",
    "## Baselines Subtask A\n",
    "\n",
    "The following two baselines have been considered by the organizers of this competition in order to provide a benchmark for the comparison of the submitted systems: \n",
    "1. The MFC (Most Frequent Classifier) baseline: Trivial model that assigns the most frequent label, estimated on the\n",
    "training set, to all the instances in the test set.\n",
    "2. The SVC (Support Vector Classifier) baseline: Linear Support Vector Machine (SVM) based on a TF-IDF representation, where the hyper-parameters are the default values set by the scikit-learn Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from evaluate.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import import_ipynb\n",
    "import evaluate # here we import the local evaluate.ipynb jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by reading the training and development data into a pandas dataframe. \n",
    "Columns TR and AG columns are removed as they are irrelevant for Subtask A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                               text  HS  TR  AG\n",
      "0      201  Hurray, saving us $$$ in so many ways @potus @...   1   0   0\n",
      "1      202  Why would young fighting age men be the vast m...   1   0   0\n",
      "2      203  @KamalaHarris Illegals Dump their Kids at the ...   1   0   0\n",
      "3      204  NY Times: 'Nearly All White' States Pose 'an A...   0   0   0\n",
      "4      205  Orban in Brussels: European leaders are ignori...   0   0   0\n",
      "...    ...                                                ...  ..  ..  ..\n",
      "8995  9196  @mmdwriter @JRubinBlogger @BenSasse I am proud...   0   0   0\n",
      "8996  9197  @CheriJacobus Hollywood is complicit in the ra...   0   0   0\n",
      "8997  9198  @amaziah_filani What a fucking cunt I hate see...   1   1   1\n",
      "8998  9199                  Hysterical woman like @CoryBooker   0   0   0\n",
      "8999  9200  Nearly every woman I know has #meToo in their ...   0   0   0\n",
      "\n",
      "[9000 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203</td>\n",
       "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204</td>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19196</td>\n",
       "      <td>@SamEnvers you unfollowed me? Fuck you pussy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>19197</td>\n",
       "      <td>@DanReynolds STFU BITCH! AND YOU GO MAKE SOME ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>19198</td>\n",
       "      <td>@2beornotbeing Honey, as a fellow white chick,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>19199</td>\n",
       "      <td>I hate bitches who talk about niggaz with kids...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19200</td>\n",
       "      <td>@AnnCoulter @DonaldJTrumpJr You won the\" life ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS\n",
       "0       201  Hurray, saving us $$$ in so many ways @potus @...   1\n",
       "1       202  Why would young fighting age men be the vast m...   1\n",
       "2       203  @KamalaHarris Illegals Dump their Kids at the ...   1\n",
       "3       204  NY Times: 'Nearly All White' States Pose 'an A...   0\n",
       "4       205  Orban in Brussels: European leaders are ignori...   0\n",
       "...     ...                                                ...  ..\n",
       "9995  19196       @SamEnvers you unfollowed me? Fuck you pussy   0\n",
       "9996  19197  @DanReynolds STFU BITCH! AND YOU GO MAKE SOME ...   1\n",
       "9997  19198  @2beornotbeing Honey, as a fellow white chick,...   0\n",
       "9998  19199  I hate bitches who talk about niggaz with kids...   1\n",
       "9999  19200  @AnnCoulter @DonaldJTrumpJr You won the\" life ...   1\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "    \n",
    "df_train = pd.read_csv('data/hateval2019_en_train.csv')\n",
    "df_dev = pd.read_csv('data/hateval2019_en_dev.csv')\n",
    "print(df_train)\n",
    "df_train_dev = df_train.append(df_dev, ignore_index=True)\n",
    "df_train_dev = df_train_dev.drop(['TR', 'AG'], axis=1)\n",
    "df_train_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The English dataset is composed out of 13.000 tweets. Out of these tweets, 10.000 are meant for training and development (9.000 training tweets + 1.000 development tweets). As expected, we have 10.000 rows in this dataframe because we have appended both training and development data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train_dev.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Plot some great visualizations with this DATA!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MFC baseline\n",
    "#### Now we will program the MFC (Most Frequent Classifier Trivial) baseline, which assigns the most frequent label, estimated on the training set, to all the instances in the test set.\n",
    "\n",
    "First, we compute the most frequent label for HS (Hate Speech), estimated on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5790\n",
      "1    4210\n",
      "Name: HS, dtype: int64\n",
      "The most frequent label for HS is: 0. This means that most tweets in the training set are not labelled as hate speech.\n"
     ]
    }
   ],
   "source": [
    "print(df_train_dev['HS'].value_counts())\n",
    "most_frequent_label = df_train_dev['HS'].value_counts().index[0]\n",
    "print(f'The most frequent label for HS is: {most_frequent_label}. This means that most tweets in the training set are not labelled as hate speech.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we read the test set into a dataframe and assign to it the most frequent label that we just computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34243</td>\n",
       "      <td>@local1025 @njdotcom @GovMurphy Oh, I could ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30593</td>\n",
       "      <td>Several of the wild fires in #california and #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31427</td>\n",
       "      <td>@JudicialWatch My question is how do you reset...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31694</td>\n",
       "      <td>#Europe, you've got a problem!   We must hurry...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31865</td>\n",
       "      <td>This is outrageous! #StopIllegalImmigration  #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>31368</td>\n",
       "      <td>you can never take a L off a real bitchðŸ˜© im ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>30104</td>\n",
       "      <td>@Brian_202 likes to call me a cunt &amp; a bitch b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>31912</td>\n",
       "      <td>@kusha1a @Camio_the_wise @shoe0nhead 1. Never ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>31000</td>\n",
       "      <td>If i see and know you a hoe why would i hit yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>30870</td>\n",
       "      <td>You be chasing them hoes fuck what a bitch think</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS\n",
       "0     34243  @local1025 @njdotcom @GovMurphy Oh, I could ha...   0\n",
       "1     30593  Several of the wild fires in #california and #...   0\n",
       "2     31427  @JudicialWatch My question is how do you reset...   0\n",
       "3     31694  #Europe, you've got a problem!   We must hurry...   0\n",
       "4     31865  This is outrageous! #StopIllegalImmigration  #...   0\n",
       "...     ...                                                ...  ..\n",
       "2995  31368  you can never take a L off a real bitchðŸ˜© im ho...   0\n",
       "2996  30104  @Brian_202 likes to call me a cunt & a bitch b...   0\n",
       "2997  31912  @kusha1a @Camio_the_wise @shoe0nhead 1. Never ...   0\n",
       "2998  31000  If i see and know you a hoe why would i hit yo...   0\n",
       "2999  30870   You be chasing them hoes fuck what a bitch think   0\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/hateval2019_en_test.csv')\n",
    "df_test = df_test.drop(['TR', 'AG'], axis=1)\n",
    "df_test_mfc = df_test.copy()\n",
    "df_test_mfc['HS'] = [most_frequent_label]*df_test_mfc.shape[0]\n",
    "df_test_mfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The macro-averaged F1 score for the MFC baseline is: 0.36708860759493667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3_\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Compute the F1-score manually\n",
    "f1_mfc = f1_score(df_test['HS'].values, df_test_mfc['HS'].values, average='macro')\n",
    "print(f'The macro-averaged F1 score for the MFC baseline is: {f1_mfc}') \n",
    "\n",
    "# Great! This corresponds with the paper!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskA_fscore: 0.36708860759493667\n",
      "taskA_precision: 0.29\n",
      "taskA_recall: 0.5\n",
      "taskA_accuracy: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3_\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# create prediction file for the mfc_baseline\n",
    "df_test_mfc[['id', 'HS']].to_csv('predictions/mfc_baseline.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_mfc[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# create file with all the evaluations for the mfc_baseline\n",
    "evaluate.write_eval(\"scores_mfc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVC baseline\n",
    "#### Now we will program the SVM (Linear Support Vector Machine) baseline, which is based on a TF-IDF representation, where the hyper-parameters are the default values set by the scikit-learn Python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The macro-averaged F1 score for the SVC baseline is: 0.3175842695733467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# First append train and test together to apply TfidfVectorizer() on them, otherwise it doesn't work (different feature sizes)\n",
    "df_train_test = df_train_dev.append(df_test, ignore_index=True) \n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_svc_train_test = vectorizer.fit_transform(df_train_test['text'].values)\n",
    "\n",
    "X_svc_train = X_svc_train_test[:10000]\n",
    "X_svc_test = X_svc_train_test[10000:]\n",
    "\n",
    "y_svc_train = df_train_dev['HS'].values\n",
    "y_svc_test = df_test['HS'].values\n",
    "\n",
    "#print(vectorizer.get_feature_names())\n",
    "\n",
    "# train classifier\n",
    "clf = SVC(probability=True, kernel='rbf') # rbf is the default kernel\n",
    "clf.fit(X_svc_train, y_svc_train)\n",
    "predictions = clf.predict_proba(X_svc_test)\n",
    "pred = [0 if x[0]>=0.5 else 1 for x in predictions]\n",
    "f1_svc = f1_score(y_svc_test, pred, average='macro')\n",
    "print(f'The macro-averaged F1 score for the SVC baseline is: {f1_svc}')\n",
    "\n",
    "# Does NOT correspond with the paper!!! (paper SVC f1-score for Subtask A: 0.451) TODO: FIX model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34243</td>\n",
       "      <td>@local1025 @njdotcom @GovMurphy Oh, I could ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30593</td>\n",
       "      <td>Several of the wild fires in #california and #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31427</td>\n",
       "      <td>@JudicialWatch My question is how do you reset...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31694</td>\n",
       "      <td>#Europe, you've got a problem!   We must hurry...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31865</td>\n",
       "      <td>This is outrageous! #StopIllegalImmigration  #...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>31368</td>\n",
       "      <td>you can never take a L off a real bitchðŸ˜© im ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>30104</td>\n",
       "      <td>@Brian_202 likes to call me a cunt &amp; a bitch b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>31912</td>\n",
       "      <td>@kusha1a @Camio_the_wise @shoe0nhead 1. Never ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>31000</td>\n",
       "      <td>If i see and know you a hoe why would i hit yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>30870</td>\n",
       "      <td>You be chasing them hoes fuck what a bitch think</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS\n",
       "0     34243  @local1025 @njdotcom @GovMurphy Oh, I could ha...   0\n",
       "1     30593  Several of the wild fires in #california and #...   0\n",
       "2     31427  @JudicialWatch My question is how do you reset...   1\n",
       "3     31694  #Europe, you've got a problem!   We must hurry...   1\n",
       "4     31865  This is outrageous! #StopIllegalImmigration  #...   1\n",
       "...     ...                                                ...  ..\n",
       "2995  31368  you can never take a L off a real bitchðŸ˜© im ho...   1\n",
       "2996  30104  @Brian_202 likes to call me a cunt & a bitch b...   1\n",
       "2997  31912  @kusha1a @Camio_the_wise @shoe0nhead 1. Never ...   1\n",
       "2998  31000  If i see and know you a hoe why would i hit yo...   1\n",
       "2999  30870   You be chasing them hoes fuck what a bitch think   1\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_svc = df_test.copy()\n",
    "df_test_svc['HS'] = pred\n",
    "df_test_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskA_fscore: 0.3175842695733467\n",
      "taskA_precision: 0.6139206970651438\n",
      "taskA_recall: 0.5070607553366174\n",
      "taskA_accuracy: 0.42933333333333334\n"
     ]
    }
   ],
   "source": [
    "# create prediction file for the svc_baseline\n",
    "df_test_svc[['id', 'HS']].to_csv('predictions/svc_baseline.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_svc[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# create file with all the evaluations for the svc_baseline\n",
    "evaluate.write_eval(\"scores_svc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524],\n",
       "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
       "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
       "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
       "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
       "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRA: Easy TF-IDF example to understand how the TfidfVectorizer() works.\n",
    "\n",
    "corpus = ['This is the first document.',\n",
    "          'This document is the second document.',\n",
    "          'And this is the third one.',\n",
    "          'Is this the first document?']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "X = X.toarray()\n",
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
