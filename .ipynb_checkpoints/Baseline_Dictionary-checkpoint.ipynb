{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thesis 2020-2021: Dictionary Baseline\n",
    "\n",
    "In this notebook, we will create a model based on a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203</td>\n",
       "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204</td>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19196</td>\n",
       "      <td>@SamEnvers you unfollowed me? Fuck you pussy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>19197</td>\n",
       "      <td>@DanReynolds STFU BITCH! AND YOU GO MAKE SOME ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>19198</td>\n",
       "      <td>@2beornotbeing Honey, as a fellow white chick,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>19199</td>\n",
       "      <td>I hate bitches who talk about niggaz with kids...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19200</td>\n",
       "      <td>@AnnCoulter @DonaldJTrumpJr You won the\" life ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS\n",
       "0       201  Hurray, saving us $$$ in so many ways @potus @...   1\n",
       "1       202  Why would young fighting age men be the vast m...   1\n",
       "2       203  @KamalaHarris Illegals Dump their Kids at the ...   1\n",
       "3       204  NY Times: 'Nearly All White' States Pose 'an A...   0\n",
       "4       205  Orban in Brussels: European leaders are ignori...   0\n",
       "...     ...                                                ...  ..\n",
       "9995  19196       @SamEnvers you unfollowed me? Fuck you pussy   0\n",
       "9996  19197  @DanReynolds STFU BITCH! AND YOU GO MAKE SOME ...   1\n",
       "9997  19198  @2beornotbeing Honey, as a fellow white chick,...   0\n",
       "9998  19199  I hate bitches who talk about niggaz with kids...   1\n",
       "9999  19200  @AnnCoulter @DonaldJTrumpJr You won the\" life ...   1\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "    \n",
    "df_train = pd.read_csv('data/hateval2019_en_train.csv')\n",
    "df_dev = pd.read_csv('data/hateval2019_en_dev.csv')\n",
    "\n",
    "df_train_dev = df_train.append(df_dev, ignore_index=True)\n",
    "df_train_dev = df_train_dev.drop(['TR', 'AG'], axis=1)\n",
    "df_train_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why would young fighting age men be the vast majority of the ones escaping a war &amp; not those who cannot fight like women, children, and the elderly?It's because the majority of the refugees are not actually refugees they are economic migrants trying to get into Europe.... https://t.co/Ks0SHbtYqn\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dev.text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING\n",
    "\n",
    "The very first step in NLP is _preprocessing_, that is, preparing the raw textual data such that we get rid of (most of the) noise and retain the most informative signal.\n",
    "\n",
    "Steps:\n",
    "- Convert to lowercase\n",
    "- Remove stopwords\n",
    "- Remove @mentions\n",
    "- Remove URL\n",
    "- Remove all non-alphanumeric symbols (except # and ')\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from pattern.text.en import singularize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Create a function to clean the tweets\n",
    "def cleanTxt(text):\n",
    "    text = text.lower() # Convert everything to lower case\n",
    "    text = re.sub(r'@[a-zA-Z0-9]+', '', text) # Remove @mentions\n",
    "    text = re.sub(r'rt[\\s]+', '', text) # Remove RT (retweet symbol)\n",
    "    text = re.sub(r'&amp;', 'and', text) # Replace '&amp;' by 'and'\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text) # Remove hyper link  \n",
    "    #text = re.sub(r'\\d+', '0', text) # Replace all numbers by a zero\n",
    "    text = \" \".join([singularize(word) for word in tokenizer.tokenize(text) if word not in stop_words]) # Remove stopwords\n",
    "    #text = \" \".join([singularize(word) for word in text])\n",
    "    text = re.sub(r'[^\\w\\s#]', ' ', text) # Remove all non-alphanumeric symbols (excluding whitespace and # characters)\n",
    "    text = re.sub(r'\\s+', ' ', text) # Replace multiple whitespaces by a single whitespace\n",
    "    text = text.strip() # Remove whitespaces at the beginning and at the end\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e13e8b1bca20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Clean the text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_train_dev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train_dev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleanTxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Show the cleaned text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_train_dev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-a6651ca34d84>\u001b[0m in \u001b[0;36mcleanTxt\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'https?:\\/\\/\\S+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Remove hyper link\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m#text = re.sub(r'\\d+', '0', text) # Replace all numbers by a zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msingularize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Remove stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m#text = \" \".join([singularize(word) for word in text])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^\\w\\s#]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Remove all non-alphanumeric symbols (excluding whitespace and # characters)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-a6651ca34d84>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'https?:\\/\\/\\S+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Remove hyper link\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m#text = re.sub(r'\\d+', '0', text) # Replace all numbers by a zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msingularize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Remove stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m#text = \" \".join([singularize(word) for word in text])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^\\w\\s#]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Remove all non-alphanumeric symbols (excluding whitespace and # characters)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop_words' is not defined"
     ]
    }
   ],
   "source": [
    "# Clean the text\n",
    "df_train_dev['text'] = df_train_dev['text'].apply(cleanTxt)\n",
    "\n",
    "# Show the cleaned text\n",
    "df_train_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary model: Attemp 1 - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all 'hateful words' from text file named profanity_en.txt\n",
    "with open('Data/profanity_en.txt') as f:\n",
    "    hs_lexicon = f.readlines()\n",
    "hs_lexicon = list(map(lambda l: l.rstrip('\\n'), hs_lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "t = TweetTokenizer()\n",
    "\n",
    "# Create a function to see if a hateful word appears in input text\n",
    "def contains_hs(text):\n",
    "    for word in t.tokenize(text):\n",
    "        if (word in hs_lexicon):\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34243</td>\n",
       "      <td>@local1025 @njdotcom @GovMurphy Oh, I could ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30593</td>\n",
       "      <td>Several of the wild fires in #california and #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31427</td>\n",
       "      <td>@JudicialWatch My question is how do you reset...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31694</td>\n",
       "      <td>#Europe, you've got a problem!   We must hurry...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31865</td>\n",
       "      <td>This is outrageous! #StopIllegalImmigration  #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>31368</td>\n",
       "      <td>you can never take a L off a real bitchðŸ˜© im ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>30104</td>\n",
       "      <td>@Brian_202 likes to call me a cunt &amp; a bitch b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>31912</td>\n",
       "      <td>@kusha1a @Camio_the_wise @shoe0nhead 1. Never ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>31000</td>\n",
       "      <td>If i see and know you a hoe why would i hit yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>30870</td>\n",
       "      <td>You be chasing them hoes fuck what a bitch think</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS\n",
       "0     34243  @local1025 @njdotcom @GovMurphy Oh, I could ha...   1\n",
       "1     30593  Several of the wild fires in #california and #...   0\n",
       "2     31427  @JudicialWatch My question is how do you reset...   1\n",
       "3     31694  #Europe, you've got a problem!   We must hurry...   0\n",
       "4     31865  This is outrageous! #StopIllegalImmigration  #...   0\n",
       "...     ...                                                ...  ..\n",
       "2995  31368  you can never take a L off a real bitchðŸ˜© im ho...   1\n",
       "2996  30104  @Brian_202 likes to call me a cunt & a bitch b...   1\n",
       "2997  31912  @kusha1a @Camio_the_wise @shoe0nhead 1. Never ...   1\n",
       "2998  31000  If i see and know you a hoe why would i hit yo...   1\n",
       "2999  30870   You be chasing them hoes fuck what a bitch think   1\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/hateval2019_en_test.csv')\n",
    "df_test = df_test.drop(['TR', 'AG', 'HS'], axis=1)\n",
    "\n",
    "df_test_contains_hs = df_test.copy()\n",
    "df_test_contains_hs['HS'] = df_test_contains_hs['text'].apply(contains_hs)\n",
    "df_test_contains_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from evaluate.ipynb\n",
      "taskA_fscore: 0.552776935073505\n",
      "taskA_precision: 0.5630655506062644\n",
      "taskA_recall: 0.5638615216201424\n",
      "taskA_accuracy: 0.553\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import evaluate # here we import the local evaluate.ipynb jupyter notebook\n",
    "\n",
    "# Create prediction file for the dictionary_baseline\n",
    "df_test_contains_hs[['id', 'HS']].to_csv('predictions/dictionary_baseline.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_contains_hs[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# Evaluate the result of the dictionary_baseline\n",
    "evaluate.write_eval(\"scores_dictionary_baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will use the same exact model, except that we will first clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34243</td>\n",
       "      <td>oh could gone taxe since current news nj guv w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30593</td>\n",
       "      <td>several wild fire #californium #colorado inten...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31427</td>\n",
       "      <td>question resettle refugee refugee go home coun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31694</td>\n",
       "      <td>#europe got problem must hurry #buildthewall b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31865</td>\n",
       "      <td>outrageou #stopillegalimmigration #meritimmigr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>31368</td>\n",
       "      <td>never take l real bitch im hotter ho chill w</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>30104</td>\n",
       "      <td>_202 like call cunt bitch tell truth can t handle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>31912</td>\n",
       "      <td>_the_wise 1 never said taught 2 called bitch f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>31000</td>\n",
       "      <td>see know hoe would hit back lol bitch got new ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>30870</td>\n",
       "      <td>chasing ho fuck bitch think</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS\n",
       "0     34243  oh could gone taxe since current news nj guv w...   1\n",
       "1     30593  several wild fire #californium #colorado inten...   1\n",
       "2     31427  question resettle refugee refugee go home coun...   1\n",
       "3     31694  #europe got problem must hurry #buildthewall b...   1\n",
       "4     31865  outrageou #stopillegalimmigration #meritimmigr...   0\n",
       "...     ...                                                ...  ..\n",
       "2995  31368       never take l real bitch im hotter ho chill w   1\n",
       "2996  30104  _202 like call cunt bitch tell truth can t handle   1\n",
       "2997  31912  _the_wise 1 never said taught 2 called bitch f...   1\n",
       "2998  31000  see know hoe would hit back lol bitch got new ...   1\n",
       "2999  30870                        chasing ho fuck bitch think   1\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_clean_contains_hs = df_test.copy()\n",
    "df_test_clean_contains_hs['text'] = df_test_clean_contains_hs['text'].apply(cleanTxt)\n",
    "df_test_clean_contains_hs['HS'] = df_test_clean_contains_hs['text'].apply(contains_hs)\n",
    "df_test_clean_contains_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskA_fscore: 0.5267674779121141\n",
      "taskA_precision: 0.598053074452919\n",
      "taskA_recall: 0.5781472359058566\n",
      "taskA_accuracy: 0.5383333333333333\n"
     ]
    }
   ],
   "source": [
    "# Create prediction file for the clean_dictionary_baseline\n",
    "df_test_clean_contains_hs[['id', 'HS']].to_csv('predictions/clean_dictionary_baseline.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_clean_contains_hs[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# Evaluate the result of the clean_dictionary_baseline\n",
    "evaluate.write_eval(\"scores_clean_dictionary_baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "- Done: Optimize the clean function cleanTxt to get better results (idea: check all tweets that have different label)\n",
    "- Done: Count amount of hateful words in tweet, normalize it, and use it as a feature (check online for best dictionary models for hate speech detection)\n",
    "- TODO: Hashtag segmentation (check if it contains hateful word; or add hateful hashtag to dictionary!) \n",
    "- Extra: Create specialized dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30593</td>\n",
       "      <td>Several of the wild fires in #california and #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31694</td>\n",
       "      <td>#Europe, you've got a problem!   We must hurry...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34192</td>\n",
       "      <td>\"GET this WORSE THAN SCUM OUT OF OUR COUNTRY! ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30910</td>\n",
       "      <td>These savages invade Our Country, disrupt citi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32884</td>\n",
       "      <td>Illegals Cross Border Just in Time to Have #An...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>33043</td>\n",
       "      <td>@pastaelitist SAME SHIT. YOU SKINNY AF BITCH I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>34113</td>\n",
       "      <td>@diianaaprince BITCH HOW DARE YOU SUPPORT NACY...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>30237</td>\n",
       "      <td>i'm so salty i tried to go in a store with no ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>31970</td>\n",
       "      <td>HOES BE WANTING YOU TO FEEL SOME TYPE OF WAY A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>32471</td>\n",
       "      <td>@MakeupWhoreder Bitch RT me one more time &amp; no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>552 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS\n",
       "1     30593  Several of the wild fires in #california and #...   0\n",
       "3     31694  #Europe, you've got a problem!   We must hurry...   0\n",
       "6     34192  \"GET this WORSE THAN SCUM OUT OF OUR COUNTRY! ...   0\n",
       "8     30910  These savages invade Our Country, disrupt citi...   0\n",
       "13    32884  Illegals Cross Border Just in Time to Have #An...   0\n",
       "...     ...                                                ...  ..\n",
       "2945  33043  @pastaelitist SAME SHIT. YOU SKINNY AF BITCH I...   0\n",
       "2947  34113  @diianaaprince BITCH HOW DARE YOU SUPPORT NACY...   0\n",
       "2953  30237  i'm so salty i tried to go in a store with no ...   0\n",
       "2979  31970  HOES BE WANTING YOU TO FEEL SOME TYPE OF WAY A...   0\n",
       "2989  32471  @MakeupWhoreder Bitch RT me one more time & no...   0\n",
       "\n",
       "[552 rows x 3 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which tweets have different label\n",
    "temp = df_test_contains_hs.loc[df_test_contains_hs['HS']!=df_test_clean_contains_hs['HS']]\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary model: Attemp 2 - count hateful words + normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "# Create a function that counts the amount of hateful words in the given text and then normalizes it by dividing it by the length of the sentence\n",
    "def count_norm(text):\n",
    "    length_text = len(text.split())\n",
    "    if (length_text == 0):\n",
    "        return 0\n",
    "    \n",
    "    count_hs = 0\n",
    "    for word in tokenizer.tokenize(text):\n",
    "        if (word in hs_lexicon):\n",
    "            count_hs += 1\n",
    "    \n",
    "    return count_hs/length_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>count_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>hurray saving u many way #lockthemup #buildthe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>would young fighting age man vast majority one...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203</td>\n",
       "      <td>illegal dump kid border like road kill refuse ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204</td>\n",
       "      <td>ny time nearly white state pose array problem ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>orban brussel european leader ignoring person ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19196</td>\n",
       "      <td>unfollowed fuck pussy</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>19197</td>\n",
       "      <td>stfu bitch go make satanic music u illuminatu ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>19198</td>\n",
       "      <td>honey fellow white chick let tell need shut fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>19199</td>\n",
       "      <td>hate bitch talk niggaz kid everybody cant find...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>19200</td>\n",
       "      <td>life time recipient hysterical woman long time...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  HS  count_norm\n",
       "0       201  hurray saving u many way #lockthemup #buildthe...   1    0.000000\n",
       "1       202  would young fighting age man vast majority one...   1    0.120000\n",
       "2       203  illegal dump kid border like road kill refuse ...   1    0.208333\n",
       "3       204  ny time nearly white state pose array problem ...   0    0.000000\n",
       "4       205  orban brussel european leader ignoring person ...   0    0.125000\n",
       "...     ...                                                ...  ..         ...\n",
       "9995  19196                              unfollowed fuck pussy   0    0.666667\n",
       "9996  19197  stfu bitch go make satanic music u illuminatu ...   1    0.437500\n",
       "9997  19198  honey fellow white chick let tell need shut fu...   0    0.217391\n",
       "9998  19199  hate bitch talk niggaz kid everybody cant find...   1    0.312500\n",
       "9999  19200  life time recipient hysterical woman long time...   1    0.000000\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dev['text'] = df_train_dev['text'].apply(cleanTxt)\n",
    "df_train_dev['count_norm'] = df_train_dev['text'].apply(count_norm)\n",
    "df_train_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.13, 0.5981759105749043),\n",
       " (0.12, 0.59526778697202),\n",
       " (0.14, 0.5947650955275953),\n",
       " (0.15, 0.5934909975256196),\n",
       " (0.11, 0.5920512026950562),\n",
       " (0.16, 0.5891847698812984),\n",
       " (0.1, 0.5875672792231293),\n",
       " (0.17, 0.5839745676420859),\n",
       " (0.09, 0.5831243432852959),\n",
       " (0.18, 0.5824054887957064),\n",
       " (0.19, 0.5781317722949599),\n",
       " (0.08, 0.5781293780089316),\n",
       " (0.2, 0.5771748063368303),\n",
       " (0.07, 0.5722968820442701),\n",
       " (0.06, 0.5693519467213115),\n",
       " (0.21, 0.5672537536556869),\n",
       " (0.05, 0.5656072617951466),\n",
       " (0.22, 0.5614772993889874),\n",
       " (0.04, 0.5592136597011159),\n",
       " (0.03, 0.5561014013541175)]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from numpy import arange\n",
    "\n",
    "# Iterate over different threshold values in save result in dictionary to find optimal threshold \n",
    "\n",
    "dict_threshold_f1 = {}\n",
    "for t in arange(0, 1, 0.01):\n",
    "    df_train_dev['HS_c'] = df_train_dev['count_norm'].apply(lambda x: 1 if (x >= t) else 0)\n",
    "    # Compute the F1-score manually\n",
    "    f1 = f1_score(df_train_dev['HS'].values, df_train_dev['HS_c'].values, average='macro')\n",
    "    dict_threshold_f1[t] = f1\n",
    "\n",
    "#dict_threshold_f1\n",
    "sort_thresholds = sorted(dict_threshold_f1.items(), key=lambda x: x[1], reverse=True)\n",
    "optimal_threshold = sort_thresholds[0][0]\n",
    "print(f'Optimal threshold is: {optimal_threshold}')\n",
    "sort_thresholds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskA_fscore: 0.5786438836298406\n",
      "taskA_precision: 0.5786389332644839\n",
      "taskA_recall: 0.5800218938149972\n",
      "taskA_accuracy: 0.5853333333333334\n"
     ]
    }
   ],
   "source": [
    "# Create new test dataframe and make HS column based on optimal threshold that we computed in previous cell\n",
    "df_test_count_norm = df_test.copy()\n",
    "df_test_count_norm['text'] = df_test_count_norm['text'].apply(cleanTxt)\n",
    "df_test_count_norm['count_norm'] = df_test_count_norm['text'].apply(count_norm)\n",
    "df_test_count_norm['HS'] = df_test_count_norm['count_norm'].apply(lambda x: 1 if (x >= optimal_threshold) else 0)\n",
    "\n",
    "# Create prediction file for the dictionary_count_norm\n",
    "df_test_count_norm[['id', 'HS']].to_csv('predictions/dictionary_count_norm.tsv', sep='\\t', index=False, header=False)\n",
    "df_test_count_norm[['id', 'HS']].to_csv('input/res/en_a.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "# Evaluate the result of the dictionary_count_norm\n",
    "evaluate.write_eval(\"scores_dictionary_count_norm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GREAT NEWS! We have slightly beaten the polarity baseline! We went from f1_score 0.57823 to 0.57864"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
